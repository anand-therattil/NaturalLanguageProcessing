{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPej/cHaT3jn1HAY5AAey3U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anand-therattil/NaturalLanguageProcessing/blob/main/NLP_feature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HOutKFsr68Qj"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "# nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-Processing \n",
        "# Keeps only alphabets and converts to lower case\n",
        "def preProcessing(sentence):\n",
        "  sentence=re.sub('[^a-zA-Z]',' ',sentence)\n",
        "  sentence= sentence.lower()\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "nWFb64PFeENE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#word_tokenize\n",
        "def stemming(sentences):\n",
        "  stemmer= PorterStemmer()\n",
        "  sentences= preProcessing(sentences)\n",
        "  words= nltk.word_tokenize(sentences)\n",
        "  features =[stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  features = \" \".join(features)\n",
        "  return features"
      ],
      "metadata": {
        "id": "YLoT_1WJ9V_X"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmetization\n",
        "def lemmatization(sentences):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  sentences= preProcessing(sentences)\n",
        "  words=nltk.word_tokenize(sentences)\n",
        "  features =[lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  features = \" \".join(features)\n",
        "  return features"
      ],
      "metadata": {
        "id": "VrBXrsU7cCw0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"The Capture of Wakefield occurred on 21 May 1643 during the First English Civil War when around 1,500 Parliamentarians under the command of Sir Thomas Fairfax (depicted) attacked the Royalist garrison of Wakefield, Yorkshire. They were outnumbered by around 3,000 Royalists led by George Goring, but successfully stormed the town. Around 800 Parliamentarians had been taken prisoner after Fairfax was defeated at Seacroft Moor, and he planned the attack to take prisoners of his own to exchange for his men. He marched his force from Leeds and divided it to attack from two different directions. After around two hours of fighting early in the morning, they broke into the town. Goring, who had been in bed suffering from either illness or a hangover, led a counterattack in his nightshirt, but to no avail. Fairfax took roughly 1,400 prisoners while, according to his own account, losing no more than seven men.\"\n",
        "sentences=nltk.sent_tokenize(text)\n",
        "corpus=list()\n",
        "for segment in sentences:\n",
        "  corpus.append(lemmatization(segment))"
      ],
      "metadata": {
        "id": "OkHQwSTU_JDF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BAG OF WORD \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv =CountVectorizer(max_features=1000)\n",
        "X= cv.fit_transform(corpus).toarray()\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqU28CiN2DfY",
        "outputId": "04d0f1ab-6183-49a0-aefb-8e00e5ba1702"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
            "  0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 2 1 1]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0\n",
            "  0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  1 1 0 0 0 0 1 1 2 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            "  0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
            " [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0\n",
            "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            "  1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5J7yObsO25H9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}